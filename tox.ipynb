{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a comment toxicity model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "insatll dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\python38\\lib\\site-packages (2.13.0)\n",
      "Collecting tensorflow-gpu\n",
      "  Using cached tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py egg_info did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [39 lines of output]\n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Python38\\lib\\site-packages\\packaging\\requirements.py\", line 35, in __init__\n",
      "          parsed = _parse_requirement(requirement_string)\n",
      "        File \"C:\\Python38\\lib\\site-packages\\packaging\\_parser.py\", line 64, in parse_requirement\n",
      "          return _parse_requirement(Tokenizer(source, rules=DEFAULT_RULES))\n",
      "        File \"C:\\Python38\\lib\\site-packages\\packaging\\_parser.py\", line 82, in _parse_requirement\n",
      "          url, specifier, marker = _parse_requirement_details(tokenizer)\n",
      "        File \"C:\\Python38\\lib\\site-packages\\packaging\\_parser.py\", line 126, in _parse_requirement_details\n",
      "          marker = _parse_requirement_marker(\n",
      "        File \"C:\\Python38\\lib\\site-packages\\packaging\\_parser.py\", line 147, in _parse_requirement_marker\n",
      "          tokenizer.raise_syntax_error(\n",
      "        File \"C:\\Python38\\lib\\site-packages\\packaging\\_tokenizer.py\", line 165, in raise_syntax_error\n",
      "          raise ParserSyntaxError(\n",
      "      packaging._tokenizer.ParserSyntaxError: Expected end or semicolon (after name and no valid version specifier)\n",
      "          python_version>\"3.7\"\n",
      "                        ^\n",
      "      \n",
      "      The above exception was the direct cause of the following exception:\n",
      "      \n",
      "      Traceback (most recent call last):\n",
      "        File \"<string>\", line 2, in <module>\n",
      "        File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "        File \"C:\\Users\\elban\\AppData\\Local\\Temp\\pip-install-svihg97h\\tensorflow-gpu_26888ba93d7b4805aa6f639cabe84b6c\\setup.py\", line 40, in <module>\n",
      "          setuptools.setup()\n",
      "        File \"C:\\Python38\\lib\\site-packages\\setuptools\\__init__.py\", line 116, in setup\n",
      "          _install_setup_requires(attrs)\n",
      "        File \"C:\\Python38\\lib\\site-packages\\setuptools\\__init__.py\", line 87, in _install_setup_requires\n",
      "          dist.parse_config_files(ignore_option_errors=True)\n",
      "        File \"C:\\Python38\\lib\\site-packages\\setuptools\\dist.py\", line 657, in parse_config_files\n",
      "          self._finalize_requires()\n",
      "        File \"C:\\Python38\\lib\\site-packages\\setuptools\\dist.py\", line 387, in _finalize_requires\n",
      "          self._normalize_requires()\n",
      "        File \"C:\\Python38\\lib\\site-packages\\setuptools\\dist.py\", line 402, in _normalize_requires\n",
      "          self.install_requires = list(map(str, _reqs.parse(install_requires)))\n",
      "        File \"C:\\Python38\\lib\\site-packages\\packaging\\requirements.py\", line 37, in __init__\n",
      "          raise InvalidRequirement(str(e)) from e\n",
      "      packaging.requirements.InvalidRequirement: Expected end or semicolon (after name and no valid version specifier)\n",
      "          python_version>\"3.7\"\n",
      "                        ^\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow tensorflow-gpu pandas matplotlib sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join('C:\\\\Users\\\\elban\\\\Downloads\\\\CommentToxicity-main\\\\CommentToxicity-main\\\\jigsaw-toxic-comment-classification-challenge','train.csv', 'train.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Preprocess "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                                  Version\n",
      "---------------------------------------- --------------------\n",
      "absl-py                                  2.1.0\n",
      "accelerate                               0.34.2\n",
      "aiohappyeyeballs                         2.4.2\n",
      "aiohttp                                  3.10.8\n",
      "aiosignal                                1.3.1\n",
      "altair                                   4.2.0\n",
      "annotated-types                          0.7.0\n",
      "anyio                                    4.5.0\n",
      "asgiref                                  3.8.1\n",
      "astunparse                               1.6.3\n",
      "async-timeout                            4.0.3\n",
      "attrs                                    24.2.0\n",
      "backoff                                  2.2.1\n",
      "backports.zoneinfo                       0.2.1\n",
      "bcrypt                                   4.2.0\n",
      "beautifulsoup4                           4.12.3\n",
      "bitsandbytes                             0.44.0\n",
      "blinker                                  1.8.2\n",
      "build                                    1.2.2\n",
      "cachetools                               5.4.0\n",
      "certifi                                  2024.7.4\n",
      "charset-normalizer                       3.3.2\n",
      "chroma-hnswlib                           0.7.6\n",
      "chromadb                                 0.5.11\n",
      "click                                    8.1.7\n",
      "colorama                                 0.4.6\n",
      "coloredlogs                              15.0.1\n",
      "contextlib2                              21.6.0\n",
      "contourpy                                1.1.1\n",
      "cycler                                   0.12.1\n",
      "Cython                                   3.0.11\n",
      "dataclasses-json                         0.5.14\n",
      "Deprecated                               1.2.14\n",
      "distro                                   1.9.0\n",
      "docstring_parser                         0.16\n",
      "durationpy                               0.8\n",
      "entrypoints                              0.4\n",
      "exceptiongroup                           1.2.2\n",
      "faiss-cpu                                1.7.4\n",
      "Faker                                    30.8.2\n",
      "fastapi                                  0.115.0\n",
      "favicon                                  0.7.0\n",
      "filelock                                 3.15.4\n",
      "Flask                                    3.0.3\n",
      "flatbuffers                              24.3.25\n",
      "fonttools                                4.51.0\n",
      "frozenlist                               1.4.1\n",
      "fsspec                                   2024.6.1\n",
      "gast                                     0.4.0\n",
      "gitdb                                    4.0.11\n",
      "GitPython                                3.1.43\n",
      "google-ai-generativelanguage             0.1.0\n",
      "google-api-core                          2.19.2\n",
      "google-api-python-client                 2.144.0\n",
      "google-auth                              2.32.0\n",
      "google-auth-httplib2                     0.2.0\n",
      "google-auth-oauthlib                     1.0.0\n",
      "google-cloud-aiplatform                  1.71.0\n",
      "google-cloud-bigquery                    3.26.0\n",
      "google-cloud-core                        2.4.1\n",
      "google-cloud-resource-manager            1.13.0\n",
      "google-cloud-storage                     2.18.2\n",
      "google-crc32c                            1.5.0\n",
      "google-generativeai                      0.1.0rc1\n",
      "google-pasta                             0.2.0\n",
      "google-resumable-media                   2.7.2\n",
      "googleapis-common-protos                 1.65.0\n",
      "graphlib_backport                        1.1.0\n",
      "greenlet                                 3.1.1\n",
      "grpc-google-iam-v1                       0.13.1\n",
      "grpcio                                   1.65.4\n",
      "grpcio-status                            1.62.3\n",
      "h11                                      0.14.0\n",
      "h5py                                     3.11.0\n",
      "htbuilder                                0.6.2\n",
      "httpcore                                 1.0.5\n",
      "httplib2                                 0.22.0\n",
      "httptools                                0.6.1\n",
      "httpx                                    0.27.2\n",
      "huggingface-hub                          0.24.2\n",
      "humanfriendly                            10.0\n",
      "idna                                     3.7\n",
      "imageio                                  2.34.1\n",
      "importlib_metadata                       8.2.0\n",
      "importlib_resources                      6.4.0\n",
      "itsdangerous                             2.2.0\n",
      "Jinja2                                   3.1.4\n",
      "jiter                                    0.7.0\n",
      "joblib                                   1.4.2\n",
      "jsonpatch                                1.33\n",
      "jsonpointer                              3.0.0\n",
      "jsonschema                               4.23.0\n",
      "jsonschema-specifications                2023.12.1\n",
      "keras                                    2.13.1\n",
      "kiwisolver                               1.4.5\n",
      "kubernetes                               31.0.0\n",
      "labelme2yolo                             0.2.5\n",
      "langchain                                0.2.16\n",
      "langchain-community                      0.2.17\n",
      "langchain-core                           0.2.41\n",
      "langchain-huggingface                    0.0.3\n",
      "langchain-text-splitters                 0.2.4\n",
      "langcodes                                3.4.1\n",
      "langsmith                                0.1.129\n",
      "language_data                            1.2.0\n",
      "lazy_loader                              0.4\n",
      "libclang                                 18.1.1\n",
      "lxml                                     5.3.0\n",
      "marisa-trie                              1.2.1\n",
      "Markdown                                 3.6\n",
      "markdown-it-py                           3.0.0\n",
      "markdownlit                              0.0.7\n",
      "MarkupSafe                               2.1.5\n",
      "marshmallow                              3.22.0\n",
      "matplotlib                               3.7.5\n",
      "mdurl                                    0.1.2\n",
      "missingno                                0.5.2\n",
      "mmh3                                     5.0.1\n",
      "monotonic                                1.6\n",
      "more-itertools                           10.5.0\n",
      "mpmath                                   1.3.0\n",
      "multidict                                6.1.0\n",
      "mypy-extensions                          1.0.0\n",
      "narwhals                                 1.8.3\n",
      "networkx                                 3.1\n",
      "nltk                                     3.8.1\n",
      "numexpr                                  2.8.6\n",
      "numpy                                    1.23.0\n",
      "oauth2client                             4.1.3\n",
      "oauthlib                                 3.2.2\n",
      "object-detection                         0.1\n",
      "onnxruntime                              1.19.2\n",
      "openai                                   1.53.0\n",
      "openapi-schema-pydantic                  1.2.4\n",
      "opentelemetry-api                        1.27.0\n",
      "opentelemetry-exporter-otlp-proto-common 1.27.0\n",
      "opentelemetry-exporter-otlp-proto-grpc   1.27.0\n",
      "opentelemetry-instrumentation            0.48b0\n",
      "opentelemetry-instrumentation-asgi       0.48b0\n",
      "opentelemetry-instrumentation-fastapi    0.48b0\n",
      "opentelemetry-proto                      1.27.0\n",
      "opentelemetry-sdk                        1.27.0\n",
      "opentelemetry-semantic-conventions       0.48b0\n",
      "opentelemetry-util-http                  0.48b0\n",
      "opt-einsum                               3.3.0\n",
      "orjson                                   3.10.7\n",
      "overrides                                7.7.0\n",
      "packaging                                24.0\n",
      "pandas                                   2.0.3\n",
      "patsy                                    0.5.6\n",
      "pillow                                   10.3.0\n",
      "pip                                      24.3.1\n",
      "pkgutil_resolve_name                     1.3.10\n",
      "plotly                                   5.24.1\n",
      "posthog                                  3.6.6\n",
      "prometheus_client                        0.21.0\n",
      "proto-plus                               1.24.0\n",
      "protobuf                                 3.20.3\n",
      "psutil                                   6.0.0\n",
      "py-cpuinfo                               9.0.0\n",
      "pyarrow                                  17.0.0\n",
      "pyasn1                                   0.6.0\n",
      "pyasn1_modules                           0.4.0\n",
      "pydantic                                 1.10.18\n",
      "pydantic_core                            2.23.4\n",
      "pydeck                                   0.9.1\n",
      "pydot                                    2.0.0\n",
      "PyDrive                                  1.3.1\n",
      "Pygments                                 2.18.0\n",
      "pymdown-extensions                       10.12\n",
      "Pympler                                  1.1\n",
      "pyparsing                                3.1.2\n",
      "PyPDF2                                   3.0.1\n",
      "PyPika                                   0.48.9\n",
      "pyproject_hooks                          1.2.0\n",
      "PyQt5                                    5.15.10\n",
      "PyQt5-Qt5                                5.15.2\n",
      "PyQt5-sip                                12.13.0\n",
      "pyreadline3                              3.5.4\n",
      "python-dateutil                          2.9.0.post0\n",
      "python-dotenv                            1.0.0\n",
      "pytz                                     2024.1\n",
      "PyWavelets                               1.4.1\n",
      "pywin32                                  308\n",
      "PyYAML                                   6.0.2\n",
      "referencing                              0.35.1\n",
      "regex                                    2024.5.15\n",
      "requests                                 2.32.3\n",
      "requests-oauthlib                        2.0.0\n",
      "rich                                     13.8.1\n",
      "rpds-py                                  0.20.0\n",
      "rsa                                      4.9\n",
      "sacrebleu                                2.2.0\n",
      "safetensors                              0.4.3\n",
      "scikit-image                             0.21.0\n",
      "scikit-learn                             1.3.2\n",
      "scipy                                    1.10.1\n",
      "seaborn                                  0.13.2\n",
      "semver                                   3.0.2\n",
      "sentence-transformers                    3.1.1\n",
      "setuptools                               75.3.0\n",
      "shapely                                  2.0.6\n",
      "shellingham                              1.5.4\n",
      "six                                      1.16.0\n",
      "smmap                                    5.0.1\n",
      "sniffio                                  1.3.1\n",
      "soupsieve                                2.6\n",
      "SQLAlchemy                               2.0.35\n",
      "st-annotated-text                        4.0.1\n",
      "st-theme                                 1.2.3\n",
      "starlette                                0.38.6\n",
      "statsmodels                              0.14.1\n",
      "streamlit                                1.39.0\n",
      "streamlit-camera-input-live              0.2.0\n",
      "streamlit-card                           1.0.2\n",
      "streamlit-embedcode                      0.1.2\n",
      "streamlit-extras                         0.5.0\n",
      "streamlit-faker                          0.0.3\n",
      "streamlit-image-coordinates              0.1.9\n",
      "streamlit-keyup                          0.2.4\n",
      "streamlit-toggle-switch                  1.0.2\n",
      "streamlit-vertical-slider                2.5.5\n",
      "sympy                                    1.13.1\n",
      "tenacity                                 8.5.0\n",
      "tensorboard                              2.13.0\n",
      "tensorboard-data-server                  0.7.2\n",
      "tensorflow                               2.13.0\n",
      "tensorflow-estimator                     2.13.0\n",
      "tensorflow-intel                         2.13.0\n",
      "tensorflow-io-gcs-filesystem             0.31.0\n",
      "termcolor                                2.4.0\n",
      "tf-estimator-nightly                     2.16.0.dev2024012409\n",
      "tf-slim                                  1.1.0\n",
      "threadpoolctl                            3.5.0\n",
      "tifffile                                 2023.7.10\n",
      "tiktoken                                 0.7.0\n",
      "tokenizers                               0.19.1\n",
      "toml                                     0.10.2\n",
      "tomli                                    2.0.1\n",
      "toolz                                    1.0.0\n",
      "torch                                    2.4.1\n",
      "torchaudio                               2.4.0\n",
      "torchvision                              0.19.1\n",
      "tornado                                  6.4.1\n",
      "tqdm                                     4.66.4\n",
      "transformers                             4.43.2\n",
      "typer                                    0.12.5\n",
      "typing_extensions                        4.12.2\n",
      "typing-inspect                           0.9.0\n",
      "tzdata                                   2024.1\n",
      "tzlocal                                  5.2\n",
      "ultralytics                              8.2.88\n",
      "ultralytics-thop                         2.0.6\n",
      "uritemplate                              4.1.1\n",
      "urllib3                                  2.2.2\n",
      "uvicorn                                  0.31.0\n",
      "validators                               0.34.0\n",
      "watchdog                                 4.0.2\n",
      "watchfiles                               0.24.0\n",
      "websocket-client                         1.8.0\n",
      "websockets                               13.1\n",
      "Werkzeug                                 3.0.3\n",
      "wheel                                    0.44.0\n",
      "wrapt                                    1.16.0\n",
      "xgboost                                  2.0.3\n",
      "yarl                                     1.13.1\n",
      "zipp                                     3.18.2\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  vectorization data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df['comment_text']\n",
    "y = df[df.columns[2:]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat',\n",
       "       'insult', 'identity_hate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 200000 # number of words in the vocab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vectorizer = TextVectorization(max_tokens=MAX_FEATURES,\n",
    "                               output_sequence_length=1800,\n",
    "                               output_mode='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.adapt(X.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_text = vectorizer(X.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(159571, 1800), dtype=int64, numpy=\n",
       "array([[  645,    76,     2, ...,     0,     0,     0],\n",
       "       [    1,    54,  2489, ...,     0,     0,     0],\n",
       "       [  425,   441,    70, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [32445,  7392,   383, ...,     0,     0,     0],\n",
       "       [    5,    12,   534, ...,     0,     0,     0],\n",
       "       [    5,     8,   130, ...,     0,     0,     0]], dtype=int64)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### crating a dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MCSHBAP - map, chache, shuffle, batch, prefetch  from_tensor_slices, list_file\n",
    "dataset = tf.data.Dataset.from_tensor_slices((vectorized_text, y))\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(160000)\n",
    "dataset = dataset.batch(16)\n",
    "dataset = dataset.prefetch(8) # helps bottlenecks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[     8,   1561,      5, ...,      0,      0,      0],\n",
       "        [    29,   7087,      9, ...,      0,      0,      0],\n",
       "        [   433,   6949,    218, ...,      0,      0,      0],\n",
       "        ...,\n",
       "        [    12,      9,     15, ...,      0,      0,      0],\n",
       "        [   104, 128420,      5, ...,      0,      0,      0],\n",
       "        [   191,    288,      5, ...,      0,      0,      0]], dtype=int64),\n",
       " array([[0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 0, 1, 0],\n",
       "        [1, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0]], dtype=int64))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split model (train, val,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset.take(int(len(dataset)*.7))\n",
    "val = dataset.skip(int(len(dataset)*.7)).take(int(len(dataset)*.2))\n",
    "test = dataset.skip(int(len(dataset)*.9)).take(int(len(dataset)*.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. create sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Bidirectional, Dense, Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The embedding layer helps the model learn relationships between words or tokens by mapping each one to a vector in a lower-dimensional space.which converts input integer tokens into dense vectors of fixed size.\n",
    "\n",
    "* This model is designed for a multi-label text classification task. The embedding layer helps the model understand word semantics, the LSTM captures sequential information, and the dense layers learn additional patterns. The final layer with sigmoid activation outputs predictions for multiple classes, which is common in cases where a single input may belong to multiple categories simultaneously.\n",
    "\n",
    "\n",
    "MAX_FEATURES+1 : for extra token : padding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "# Create the embedding layer \n",
    "model.add(Embedding(MAX_FEATURES+1, 32))\n",
    "\n",
    "# Bidirectional LSTM Layer\n",
    "model.add(Bidirectional(LSTM(32, activation='tanh')))\n",
    "\n",
    "# Feature extractor Fully connected layers\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# Final layer \n",
    "model.add(Dense(6, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='BinaryCrossentropy', optimizer='Adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,400,032</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">774</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1800\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │     \u001b[38;5;34m6,400,032\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m16,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m774\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,475,060</span> (74.29 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,475,060\u001b[0m (74.29 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,491,686</span> (24.76 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,491,686\u001b[0m (24.76 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,983,374</span> (49.53 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m12,983,374\u001b[0m (49.53 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m6981/6981\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step - loss: 0.0718"
     ]
    }
   ],
   "source": [
    "history = model.fit(train, epochs=5, validation_data=val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m----> 2\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory)\u001b[38;5;241m.\u001b[39mplot()\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "pd.DataFrame(history.history).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.make predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = vectorizer('You freaking suck!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"sequential_1_1/Cast:0\", shape=(32,), dtype=float32). Expected shape (None, 1800), but input has incompatible shape (32,)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(32,), dtype=int64)\n  • training=False\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_text\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\elban\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\elban\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\functional.py:244\u001b[0m, in \u001b[0;36mFunctional._adjust_input_rank\u001b[1;34m(self, flat_inputs)\u001b[0m\n\u001b[0;32m    242\u001b[0m             adjusted\u001b[38;5;241m.\u001b[39mappend(ops\u001b[38;5;241m.\u001b[39mexpand_dims(x, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    243\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    245\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid input shape for input \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Expected shape \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mref_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but input has incompatible shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    247\u001b[0m     )\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# Add back metadata.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(flat_inputs)):\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"sequential_1_1/Cast:0\", shape=(32,), dtype=float32). Expected shape (None, 1800), but input has incompatible shape (32,)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(32,), dtype=int64)\n  • training=False\n  • mask=None"
     ]
    }
   ],
   "source": [
    "res = model.predict(input_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(res > 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X, batch_y = test.as_numpy_iterator().next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(model.predict(batch_X) > 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = Precision()\n",
    "re = Recall()\n",
    "acc = CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test.as_numpy_iterator(): \n",
    "\n",
    "    # Unpack the batch \n",
    "    X_true, y_true = batch\n",
    "    \n",
    "    # Make a prediction \n",
    "    yhat = model.predict(X_true)\n",
    "    \n",
    "    # Flatten the predictions\n",
    "    y_true = y_true.flatten()\n",
    "    yhat = yhat.flatten()\n",
    "    \n",
    "    pre.update_state(y_true, yhat)\n",
    "    re.update_state(y_true, yhat)\n",
    "    acc.update_state(y_true, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Precision: {pre.result().numpy()}, Recall:{re.result().numpy()}, Accuracy:{acc.result().numpy()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gradio jinja2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('toxicity.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('toxicity.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str = vectorizer('hey i freaken hate you!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.predict(np.expand_dims(input_str,0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_comment(comment):\n",
    "    vectorized_comment = vectorizer([comment])\n",
    "    results = model.predict(vectorized_comment)\n",
    "    \n",
    "    text = ''\n",
    "    for idx, col in enumerate(df.columns[2:]):\n",
    "        text += '{}: {}\\n'.format(col, results[0][idx]>0.5)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interface = gr.Interface(fn=score_comment, \n",
    "                         inputs=gr.inputs.Textbox(lines=2, placeholder='Comment to score'),\n",
    "                        outputs='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
